{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a672e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ffbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(track_id):\n",
    "    random.seed(track_id) \n",
    "    return (random.randint(64, 255), random.randint(64, 255), random.randint(64, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_rate_log = deque(maxlen=20)  # Store (timestamp, vehicle_count)\n",
    "jam_threshold = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b969c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Initialize model and tracker\n",
    "model = YOLO('best_mosaic.pt')\n",
    "tracker = DeepSort(max_age=30)\n",
    "\n",
    "# Store past trajectories\n",
    "trajectories = defaultdict(list)\n",
    "id_colors = {}  # Store color for each ID\n",
    "timestamps = {} \n",
    "LINE_Y = 500\n",
    "# Load your video\n",
    "cap = cv2.VideoCapture(r\"extracted_folder\\traffic.mp4\")\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "out = cv2.VideoWriter('output_analysis.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "total_count = 0 \n",
    "visible_count = 0 \n",
    "last_positions={}\n",
    "FAST_THRESHOLD=150\n",
    "SLOW_THRESHOLD=60\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Get YOLO detections\n",
    "    results = model(frame)\n",
    "    detections = []\n",
    "    vehicle_centers=[]\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "            vehicle_centers.append([cx, cy])\n",
    "            conf = float(box.conf[0])\n",
    "            cls = int(box.cls[0])\n",
    "            detections.append(([x1, y1, x2 - x1, y2 - y1], conf, cls))\n",
    "    vehicle_centers = np.array(vehicle_centers)\n",
    "\n",
    "# Step 2: DBSCAN clustering\n",
    "    if len(vehicle_centers) > 0:\n",
    "        clustering = DBSCAN(eps=100, min_samples=2).fit(vehicle_centers)\n",
    "        labels = clustering.labels_\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        colors = plt.cm.get_cmap('tab20', n_clusters if n_clusters > 0 else 1)\n",
    "\n",
    "    # Step 3: Draw cluster circles\n",
    "    for (cx, cy), label in zip(vehicle_centers, labels):\n",
    "        if label == -1:\n",
    "            color = (128, 128, 128)  # noise\n",
    "        else:\n",
    "            c = colors(label)\n",
    "            color = (int(c[2]*255), int(c[1]*255), int(c[0]*255))\n",
    "        cv2.circle(frame, (cx, cy), 10, color, -1)\n",
    "        cv2.putText(frame, f'{label}', (cx - 10, cy - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # Update tracks\n",
    "    counted_ids = set()\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "    active_track_ids = set()  # <--- FIXED: properly initialize\n",
    "    cv2.line(frame, (0, LINE_Y), (frame.shape[1], LINE_Y), (0, 255, 255), 2)\n",
    "\n",
    "     # ← add before the loop\n",
    "\n",
    "    visible_count = 0  # count of vehicles currently in frame\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update > 0:\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        active_track_ids.add(track_id)\n",
    "\n",
    "        l, t, r, b = track.to_ltrb()\n",
    "        center_x = int((l + r) / 2)\n",
    "        center_y = int((t + b) / 2)\n",
    "\n",
    "        # Color assignment\n",
    "        if track_id not in id_colors:\n",
    "            id_colors[track_id] = get_color(track_id)\n",
    "        color = id_colors[track_id]\n",
    "\n",
    "\n",
    "        # Count logic using movement across the line\n",
    "        prev_pos = last_positions.get(track_id)\n",
    "        if prev_pos:\n",
    "            prev_y = prev_pos[1]\n",
    "            # Count if object moved from above to below the line\n",
    "            if prev_y < LINE_Y and center_y >= LINE_Y and track_id not in counted_ids:\n",
    "                counted_ids.add(track_id)\n",
    "                total_count += 1\n",
    "        last_positions[track_id] = (center_x, center_y)\n",
    "\n",
    "        visible_count += 1\n",
    "            \n",
    "        \n",
    "\n",
    "        # Store current position\n",
    "        trajectories[track_id].append((center_x, center_y))\n",
    "        # --- Access Kalman filter velocity (vx, vy) ---\n",
    "        if hasattr(track, 'mean'):  # Ensure internal state exists\n",
    "            vx = track.mean[4]  # Velocity in x-direction (pixels/frame)\n",
    "            vy = track.mean[5]  # Velocity in y-direction\n",
    "            vel = (vx**2 + vy**2) ** 0.5  # Euclidean speed in pixels/frame\n",
    "\n",
    "            # Convert to pixels/second using FPS\n",
    "             # Fallback to 30 if unknown\n",
    "            speed_kalman = vel * fps\n",
    "            if speed_kalman < SLOW_THRESHOLD:\n",
    "                speed_category = \"Slow\"\n",
    "                speed_color = (255, 0, 0)\n",
    "            elif speed_kalman > FAST_THRESHOLD:\n",
    "                speed_category = \"Fast\"\n",
    "                speed_color = (0, 0, 255)\n",
    "            else:\n",
    "                speed_category = \"Medium\"\n",
    "                speed_color = (0, 255, 255)\n",
    "\n",
    "            cv2.putText(frame, f\"{speed_category}\", (center_x, center_y + 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, speed_color, 2)\n",
    "            # Display speed from Kalman velocity\n",
    "            cv2.putText(frame, f\"KF:{speed_kalman:.1f} px/s\", (center_x,center_y+25 ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 128, 255), 1)\n",
    "\n",
    "\n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(frame, (int(l), int(t)), (int(r), int(b)), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"ID: {track_id}\", (int(l), int(t) - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "        # Draw trajectory history\n",
    "        for i in range(1, len(trajectories[track_id])):\n",
    "            cv2.line(frame, trajectories[track_id][i - 1], trajectories[track_id][i], color, 2)\n",
    "            \n",
    "        # Draw predicted next location\n",
    "        \n",
    "\n",
    "        for i in range(1, len(trajectories[track_id])):\n",
    "            cv2.line(frame, trajectories[track_id][i - 1], trajectories[track_id][i], color, 2)\n",
    "            cv2.arrowedLine(frame, trajectories[track_id][i - 1], trajectories[track_id][i], (0, 255, 0), 2, tipLength=0.5)\n",
    "      \n",
    "\n",
    "    #  Move this outside the track loop\n",
    "    for track_id in list(trajectories.keys()):\n",
    "        if track_id not in active_track_ids:\n",
    "            del trajectories[track_id]\n",
    "    cv2.putText(frame, f\"Total Vehicles Passed: {total_count}\", (30, 50),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.putText(frame, f\"Vehicles in Frame: {visible_count}\", (30, 100),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    # Traffic Flow Rate Calculation\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Only log once per second\n",
    "    if not vehicle_rate_log or current_time - vehicle_rate_log[-1][0] >= 1:\n",
    "        vehicle_rate_log.append((current_time, total_count))\n",
    "\n",
    "    # Compute smoothed dN/dt if enough data\n",
    "    if len(vehicle_rate_log) >= 2:\n",
    "        rates = []\n",
    "        for i in range(len(vehicle_rate_log) - 1):\n",
    "            t1, n1 = vehicle_rate_log[i]\n",
    "            t2, n2 = vehicle_rate_log[i + 1]\n",
    "            dt = t2 - t1\n",
    "            dn = n2 - n1\n",
    "            if dt > 0:\n",
    "                rates.append(dn / dt)\n",
    "\n",
    "        if rates:\n",
    "            avg_rate = sum(rates) / len(rates)\n",
    "\n",
    "            # Display the smoothed rate\n",
    "            cv2.putText(frame, f\"Flow Rate: {avg_rate:.2f} veh/s\", (30, 130),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 128, 0), 2)\n",
    "\n",
    "            # Jam Detection\n",
    "            if avg_rate < jam_threshold and avg_rate!=0:\n",
    "                cv2.putText(frame, \"Low flow\", (30, 170),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
    "    cv2.line(frame, (0, LINE_Y), (frame.shape[1], LINE_Y), (0, 255, 255), 2)\n",
    "    out.write(frame)\n",
    "    cv2.imshow(\"Tracking with Trajectories + Prediction\", frame)\n",
    "    if cv2.waitKey(1) == 27:  # ESC to quit\n",
    "                    break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
